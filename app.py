import streamlit as st
import os
import json
import numpy as np
import faiss
import time
import pickle
from pathlib import Path
from io import BytesIO
from typing import List, Dict, Any
from PyPDF2 import PdfReader
from docx import Document
import matplotlib.pyplot as plt
from scipy.interpolate import make_interp_spline
from openai import OpenAI

# ==========================================
# 0. åŸºç¡€é…ç½®ä¸æŒä¹…åŒ–è·¯å¾„
# ==========================================
st.set_page_config(
    page_title="èŒ¶é¥®å…­å› å­AIè¯„åˆ†å™¨ (Local Pro)",
    page_icon="ğŸµ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å®šä¹‰è®°å¿†å­˜å‚¨ç›®å½•
DATA_DIR = Path("./tea_data")
DATA_DIR.mkdir(exist_ok=True) 

# å®šä¹‰æ–‡ä»¶è·¯å¾„
PATHS = {
    "kb_index": DATA_DIR / "kb.index",
    "kb_chunks": DATA_DIR / "kb_chunks.pkl",
    "case_index": DATA_DIR / "cases.index",
    "case_data": DATA_DIR / "cases.json",
    # æ³¨æ„ï¼šè¿™é‡Œæ”¹ä¸º LLaMA-Factory å…¼å®¹çš„è®­ç»ƒæ•°æ®è·¯å¾„
    "training_data": DATA_DIR / "tea_finetune.json", 
    "prompt": DATA_DIR / "prompts.json"
}

# æ ·å¼
st.markdown("""
    <style>
    .main-title {font-size: 2.5em; font-weight: bold; text-align: center; color: #2E7D32; margin-bottom: 0.5em;}
    .slogan {font-size: 1.2em; font-style: italic; text-align: center; color: #558B2F; margin-bottom: 30px; font-family: "KaiTi", "æ¥·ä½“", serif;}
    .factor-card {background-color: #F1F8E9; padding: 15px; border-radius: 10px; margin-bottom: 10px; border-left: 5px solid #4CAF50;}
    .score-header {display:flex; justify-content:space-between; font-weight:bold; color:#2E7D32;}
    .advice-tag {font-size: 0.85em; padding: 2px 6px; border-radius: 4px; margin-top: 5px; background-color: #fff; border: 1px dashed #4CAF50; color: #388E3C; display: inline-block;}
    .master-comment {background-color: #FFFDE7; border: 1px solid #FFF9C4; padding: 15px; border-radius: 8px; font-family: "KaiTi", serif; font-size: 1.1em; color: #5D4037; margin-bottom: 20px; line-height: 1.6;}
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 1. æ ¸å¿ƒæ•°æ®ç®¡ç†
# ==========================================

class DataManager:
    @staticmethod
    def save(index, data, idx_path, data_path, is_json=False):
        if index: faiss.write_index(index, str(idx_path))
        with open(data_path, "w" if is_json else "wb") as f:
            if is_json: json.dump(data, f, ensure_ascii=False, indent=2)
            else: pickle.dump(data, f)
    
    @staticmethod
    def load(idx_path, data_path, is_json=False):
        if idx_path.exists() and data_path.exists():
            try:
                index = faiss.read_index(str(idx_path))
                with open(data_path, "r" if is_json else "rb") as f:
                    data = json.load(f) if is_json else pickle.load(f)
                return index, data
            except: pass
        # é»˜è®¤è¿”å› 384 ç»´ç´¢å¼• (é€‚é… all-MiniLM-L6-v2)
        # å¦‚æœä½ ä¹‹å‰è¿è¡Œè¿‡æ—§ä»£ç ï¼Œå»ºè®®åˆ é™¤ ./tea_data ä¸‹çš„ .index æ–‡ä»¶é‡æ–°ç”Ÿæˆï¼Œå¦åˆ™ç»´åº¦ä¸åŒ¹é…ä¼šæŠ¥é”™
        return faiss.IndexFlatL2(384), [] 
    
    @staticmethod
    def append_to_finetune_dataset(user_input, scores, system_prompt, master_comment):
        """
        æ ¸å¿ƒå¾®è°ƒé€»è¾‘ï¼šå°†æ ¡å‡†åçš„æ•°æ®ä¿å­˜ä¸º LLaMA-Factory å…¼å®¹çš„ Alpaca æ ¼å¼ (JSON List)
        """
        try:
            # 1. æ„é€ æœŸæœ›çš„æ¨¡å‹è¾“å‡º (JSON)
            target_output = json.dumps({
                "master_comment": master_comment,
                "scores": scores
            }, ensure_ascii=False)
            
            # 2. æ„é€ ä¸€æ¡è®­ç»ƒæ•°æ®
            new_entry = {
                "instruction": system_prompt,
                "input": user_input,
                "output": target_output
            }
            
            # 3. è¯»å–ç°æœ‰æ–‡ä»¶æˆ–åˆ›å»ºæ–°åˆ—è¡¨
            current_data = []
            if PATHS['training_data'].exists():
                try:
                    with open(PATHS['training_data'], "r", encoding="utf-8") as f:
                        current_data = json.load(f)
                        if not isinstance(current_data, list): current_data = []
                except: current_data = []
            
            # 4. è¿½åŠ å¹¶ä¿å­˜
            current_data.append(new_entry)
            with open(PATHS['training_data'], "w", encoding="utf-8") as f:
                json.dump(current_data, f, ensure_ascii=False, indent=2)
            
            return len(current_data)
        except Exception as e:
            print(f"[ERROR] append_to_finetune å¤±è´¥: {str(e)}")
            return 0

# æœ¬åœ° Embedderï¼Œä½¿ç”¨ sentence-transformers
class LocalEmbedder:
    def __init__(self):
        try:
            from sentence_transformers import SentenceTransformer
            # ä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼Œé€Ÿåº¦å¿«ï¼Œé€‚åˆ CPU/å•å¡
            # ç¬¬ä¸€æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ (~80MB)
            self.model = SentenceTransformer('all-MiniLM-L6-v2') 
            self.dim = 384
        except Exception as e:
            st.error(f"Embedding æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·ç¡®ä¿å®‰è£…äº† sentence-transformers: {e}")
            self.model = None
            self.dim = 384

    def encode(self, texts: List[str]) -> np.ndarray:
        if not texts or not self.model: return np.zeros((0, self.dim), dtype="float32")
        if isinstance(texts, str): texts = [texts]
        try:
            embeddings = self.model.encode(texts)
            return np.array(embeddings).astype("float32")
        except: 
            return np.zeros((len(texts), self.dim), dtype="float32")

# é»˜è®¤ Prompt (ä¿æŒä¸å˜)
DEFAULT_PROMPT_CONFIG = {
    "system_template": """ä½ æ˜¯ä¸€åèµ„æ·±çš„èŒ¶é¥®äº§å“ç ”å‘ä¸æ„Ÿå®˜åˆ†æä¸“å®¶ã€‚
è¯·åŸºäºç»™å®šçš„äº§å“æè¿°ã€å‚è€ƒèµ„æ–™å’Œç›¸ä¼¼å†å²åˆ¤ä¾‹ï¼Œä¸¥æ ¼æŒ‰ç…§"ç½—é©¬æµ‹è¯„æ³•2.0"è¿›è¡Œä¸“ä¸šè¯„åˆ†ã€‚

====================
ä¸€ã€è¯„åˆ†æ–¹æ³•
====================
å…­å› å­ï¼ˆ0-9åˆ†ï¼‰ï¼š
1. ä¼˜é›…æ€§ï¼šé¦™æ°”æ„‰æ‚¦æ„Ÿ
2. è¾¨è¯†åº¦ï¼šé¦™æ°”è®°å¿†ç‚¹
3. åè°ƒæ€§ï¼šèåˆåº¦
4. é¥±å’Œåº¦ï¼šæµ“åšåº¦
5. æŒä¹…æ€§ï¼šä½™éŸµ
6. è‹¦æ¶©åº¦ï¼šèˆ’é€‚åº¦ï¼ˆåˆ†æ•°è¶Šé«˜è¶Šèˆ’é€‚ï¼Œè¶Šä¸è‹¦ï¼‰

====================
äºŒã€è¾“å‡ºçº¦æŸ
====================
è¯·ç›´æ¥è¾“å‡º JSON æ ¼å¼ï¼ŒåŒ…å« "master_comment" å’Œ "scores" ä¸¤ä¸ªå­—æ®µã€‚ä¸è¦è¾“å‡ºä»»ä½• Markdown æ ‡è®°æˆ–å¤šä½™çš„è§£é‡Šã€‚""",
    
    "user_template": """ã€å¾…è¯„åˆ†äº§å“ã€‘
{product_desc}

ã€å‚è€ƒæ ‡å‡†ã€‘
{context_text}

ã€å†å²åˆ¤ä¾‹ã€‘
{case_text}

è¯·è¾“å‡ºJSONç»“æœï¼š"""
}

# ==========================================
# 2. é€»è¾‘å‡½æ•°
# ==========================================

# æ ¸å¿ƒè¯„åˆ†å‡½æ•°
def run_scoring(text, kb_res, case_res, prompt_cfg, embedder, client, model_id, r_num, c_num): 
    vec = embedder.encode([text])
    
    # RAG æ£€ç´¢
    ctx_txt, hits = "ï¼ˆæ— èµ„æ–™ï¼‰", []
    if kb_res[0].ntotal > 0: 
        _, idx = kb_res[0].search(vec, r_num)
        hits = [kb_res[1][i] for i in idx[0] if i < len(kb_res[1]) and i >= 0]
        if hits: ctx_txt = "\n".join([f"- {h[:150]}..." for h in hits])
        
    # åˆ¤ä¾‹æ£€ç´¢
    case_txt, found_cases = "ï¼ˆæ— åˆ¤ä¾‹ï¼‰", []
    if case_res[0].ntotal > 0: 
        _, idx = case_res[0].search(vec, c_num)
        for i in idx[0]:
            if i < len(case_res[1]) and i >= 0:
                c = case_res[1][i]
                found_cases.append(c)
                # ç®€åŒ–åˆ¤ä¾‹å±•ç¤ºï¼ŒèŠ‚çœ Context Window
                sc = c.get('scores', {})
                u_sc = sc.get('ä¼˜é›…æ€§',{}).get('score', '-')
                case_txt += f"\n- {c['text'][:30]}... (ä¼˜é›…:{u_sc})"

    sys_p = prompt_cfg.get('system_template', DEFAULT_PROMPT_CONFIG['system_template'])
    user_p = prompt_cfg.get('user_template', DEFAULT_PROMPT_CONFIG['user_template']).format(
        product_desc=text, context_text=ctx_txt, case_text=case_txt
    )

    try:
        # è°ƒç”¨æœ¬åœ° vLLM
        resp = client.chat.completions.create(
            model=model_id, 
            messages=[{"role":"system", "content":sys_p}, {"role":"user", "content":user_p}],
            temperature=0.3,
            max_tokens=1024,
            # Qwen2.5 æ”¯æŒ json_object æ¨¡å¼ï¼Œç¡®ä¿è¾“å‡ºæ ¼å¼ç¨³å®š
            response_format={"type": "json_object"} 
        )
        content = resp.choices[0].message.content
        return json.loads(content), hits, found_cases
    except Exception as e:
        st.error(f"æ¨ç†é”™è¯¯ (è¯·æ£€æŸ¥ vLLM æ˜¯å¦å¯åŠ¨): {e}")
        return None, [], []

# é£å‘³å½¢æ€å›¾
def calculate_section_scores(scores):
    s = scores["scores"]
    def g(k): return s.get(k, {}).get("score", 0)
    top  = (g("ä¼˜é›…æ€§") + g("è¾¨è¯†åº¦")) / 2
    mid  = (g("åè°ƒæ€§") + g("é¥±å’Œåº¦")) / 2
    base = (g("æŒä¹…æ€§") + g("è‹¦æ¶©åº¦")) / 2
    return top, mid, base

def plot_flavor_shape(scores_data):
    top, mid, base = calculate_section_scores(scores_data)
    fig, ax = plt.subplots(figsize=(4, 5))
    fig.patch.set_alpha(0)
    ax.patch.set_alpha(0)
    y = np.array([1, 2, 3]) 
    x = np.array([base, mid, top])
    y_new = np.linspace(1, 3, 300)
    try:
        spl = make_interp_spline(y, x, k=2)
        x_smooth = spl(y_new)
    except:
        x_smooth = np.interp(y_new, y, x)
    x_smooth = np.maximum(x_smooth, 0.1)
    
    # ç®€å•çš„å¯è§†åŒ–å¡«å……
    ax.fill_betweenx(y_new, -x_smooth, x_smooth, color='#4CAF50', alpha=0.6)
    ax.text(0, 2.7, f"å‰è°ƒ {top:.1f}", ha='center', color='white', fontweight='bold')
    ax.text(0, 2.0, f"ä¸­è°ƒ {mid:.1f}", ha='center', color='white', fontweight='bold')
    ax.text(0, 1.3, f"åè°ƒ {base:.1f}", ha='center', color='white', fontweight='bold')
    ax.axis('off')
    ax.set_xlim(-10, 10)
    return fig

# ==========================================
# 3. é¡µé¢åˆå§‹åŒ–
# ==========================================

if'loaded' not in st.session_state:
    # ç¬¬ä¸€æ¬¡åŠ è½½æ—¶ï¼Œå¦‚æœå‘ç° index ç»´åº¦ä¸åŒ¹é…ï¼ˆä¾‹å¦‚ä¹‹å‰æ˜¯1024ï¼Œç°åœ¨æ˜¯384ï¼‰ï¼Œéœ€è¦å¤„ç†
    # è¿™é‡Œç®€å•å¤„ç†ï¼šå¦‚æœæŠ¥é”™å°±é‡å»ºç©ºçš„
    try:
        kb_idx, kb_data = DataManager.load(PATHS['kb_index'], PATHS['kb_chunks'])
    except:
        kb_idx, kb_data = faiss.IndexFlatL2(384), []
        
    try:
        case_idx, case_data = DataManager.load(PATHS['case_index'], PATHS['case_data'], is_json=True)
    except:
        case_idx, case_data = faiss.IndexFlatL2(384), []

    st.session_state.kb = (kb_idx, kb_data)
    st.session_state.cases = (case_idx, case_data)
    
    if PATHS['prompt'].exists():
        try:
            with open(PATHS['prompt'], 'r') as f: st.session_state.prompt_config = json.load(f)
        except: st.session_state.prompt_config = DEFAULT_PROMPT_CONFIG.copy()
    else:
        st.session_state.prompt_config = DEFAULT_PROMPT_CONFIG.copy()
    
    # åˆå§‹åŒ– Embedder
    st.session_state.embedder = LocalEmbedder()
    
    st.session_state.loaded = True

# åˆå§‹åŒ– OpenAI Client (æŒ‡å‘ vLLM)
# è¯·ç¡®ä¿ä½ çš„ vLLM æ­£åœ¨è¿è¡Œäº port 8000
client = OpenAI(
    api_key="EMPTY", 
    base_url="http://localhost:8000/v1"
)

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ æœ¬åœ°é…ç½®")
    st.success("ğŸŸ¢ å·²è¿æ¥æœ¬åœ° vLLM")
    
    model_name = "Qwen2.5-7B-Instruct" # å¿…é¡»ä¸ vLLM å¯åŠ¨å‚æ•°ä¸€è‡´
    st.caption(f"å½“å‰æ¨¡å‹: {model_name}")
    
    st.markdown("---")
    st.markdown("**æ•°æ®ç»Ÿè®¡**")
    st.caption(f"RAGç‰‡æ®µ: {len(st.session_state.kb[1])} æ¡")
    st.caption(f"å†å²åˆ¤ä¾‹: {len(st.session_state.cases[1])} æ¡")
    
    if PATHS['training_data'].exists():
        try:
            with open(PATHS['training_data'], 'r') as f:
                d = json.load(f)
            st.caption(f"ğŸ’ª **å¾…å¾®è°ƒæ•°æ®: {len(d)} æ¡**")
        except: pass
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰æ•°æ® (æ…ç‚¹)"):
        import shutil
        shutil.rmtree(DATA_DIR)
        DATA_DIR.mkdir()
        st.warning("æ•°æ®å·²æ¸…ç©ºï¼Œè¯·åˆ·æ–°é¡µé¢")

st.markdown('<div class="main-title">ğŸµ èŒ¶å“ AI è¯„åˆ†å™¨ (vLLMç‰ˆ)</div>', unsafe_allow_html=True)

# ==========================================
# 4. åŠŸèƒ½æ ‡ç­¾é¡µ
# ==========================================
tab1, tab2 = st.tabs(["ğŸ’¡ äº¤äº’è¯„åˆ†ä¸æ ¡å‡†", "ğŸš€ å¾®è°ƒæ•°æ®ä¸­å¿ƒ"])

# --- Tab 1: äº¤äº’è¯„åˆ† ---
with tab1:
    st.info("ğŸ’¡ æµç¨‹ï¼šè¾“å…¥èŒ¶è¯„ -> AI è¯„åˆ† -> **ä¸“å®¶äººå·¥æ ¡å‡†** -> å­˜å…¥è®­ç»ƒåº“")
    
    col1, col2 = st.columns([2, 1])
    with col1:
        # ä½¿ç”¨ Session State ä¿æŒè¾“å…¥
        if'user_input' not in st.session_state: st.session_state.user_input = ""
        user_input = st.text_area("è¾“å…¥èŒ¶è¯„æè¿°:", value=st.session_state.user_input, height=120)
        st.session_state.user_input = user_input
        
        if st.button("ğŸš€ å¼€å§‹è¯„åˆ†", type="primary"):
            if not user_input: st.warning("è¯·è¾“å…¥å†…å®¹")
            else:
                with st.spinner(f"AI æ­£åœ¨æ€è€ƒ..."):
                    scores, kb_hits, case_hits = run_scoring(
                        user_input, st.session_state.kb, st.session_state.cases,
                        st.session_state.prompt_config, st.session_state.embedder, client, model_name, 3, 2
                    )
                    if scores:
                        st.session_state.last_scores = scores
                        st.session_state.last_master = scores.get("master_comment", "")
                        st.rerun() # åˆ·æ–°é¡µé¢æ˜¾ç¤ºç»“æœ

    # æ˜¾ç¤ºç»“æœåŒºåŸŸ
    if'last_scores' in st.session_state and st.session_state.last_scores:
        scores = st.session_state.last_scores
        
        st.markdown("---")
        st.subheader("ğŸ“Š è¯„åˆ†ç»“æœ (è¯·ä¸“å®¶æ ¡å‡†)")
        
        # å·¦å³åˆ†æ ï¼šå·¦è¾¹æ˜¯å¯è§†åŒ–ï¼Œå³è¾¹æ˜¯æ ¡å‡†è¡¨å•
        res_col1, res_col2 = st.columns([1, 2])
        
        with res_col1:
            st.markdown(f"**AI ç”Ÿæˆæ€»è¯„:**\n\n> {st.session_state.last_master}")
            fig = plot_flavor_shape(scores)
            st.pyplot(fig)
        
        with res_col2:
            with st.form("calibration_form"):
                st.markdown("#### âœï¸ ä¸“å®¶æ ¡å‡†é¢æ¿")
                st.caption("è¯·ä¿®æ­£ AI çš„è¯„åˆ†ï¼Œæ‚¨çš„ä¿®æ­£å°†æˆä¸ºæ¨¡å‹å˜å¼ºçš„å…»æ–™ã€‚")
                
                # 1. æ ¡å‡†æ€»è¯„
                new_master = st.text_area("å®—å¸ˆæ€»è¯„ (æ ¡å‡†)", value=st.session_state.last_master, height=80)
                
                # 2. æ ¡å‡†å…­å› å­
                factors = ["ä¼˜é›…æ€§", "è¾¨è¯†åº¦", "åè°ƒæ€§", "é¥±å’Œåº¦", "æŒä¹…æ€§", "è‹¦æ¶©åº¦"]
                s_dict = scores.get("scores", {})
                new_scores = {}
                
                c1, c2 = st.columns(2)
                for i, f in enumerate(factors):
                    with (c1 if i % 2 == 0 else c2):
                        current_data = s_dict.get(f, {})
                        val = st.slider(f"{f}", 0, 9, int(current_data.get("score", 5)))
                        cmt = st.text_input(f"è¯„è¯­ ({f})", current_data.get("comment", ""))
                        sug = st.text_input(f"å»ºè®® ({f})", current_data.get("suggestion", ""))
                        
                        new_scores[f] = {"score": val, "comment": cmt, "suggestion": sug}
                
                submitted = st.form_submit_button("âœ… ç¡®è®¤æ ¡å‡†å¹¶ä¿å­˜åˆ°è®­ç»ƒåº“", type="primary")
                
                if submitted:
                    # ä¿å­˜åˆ°å¾®è°ƒæ•°æ®æ–‡ä»¶
                    sys_p = st.session_state.prompt_config['system_template']
                    count = DataManager.append_to_finetune_dataset(
                        user_input, new_scores, sys_p, new_master
                    )
                    
                    # åŒæ—¶ä¹Ÿä¿å­˜åˆ°åˆ¤ä¾‹åº“ (RAG)
                    new_case = {"text": user_input, "scores": new_scores, "master_comment": new_master, "tags": "äººå·¥æ ¡å‡†"}
                    st.session_state.cases[1].append(new_case)
                    vec = st.session_state.embedder.encode([user_input])
                    st.session_state.cases[0].add(vec)
                    DataManager.save(st.session_state.cases[0], st.session_state.cases[1], PATHS['case_index'], PATHS['case_data'], is_json=True)
                    
                    st.success(f"ğŸ‰ ä¿å­˜æˆåŠŸï¼å½“å‰è®­ç»ƒæ•°æ®é‡: {count} æ¡")
                    time.sleep(1)
                    st.rerun()

# --- Tab 2: å¾®è°ƒæ•°æ®ä¸­å¿ƒ ---
with tab2:
    st.header("ğŸ­ å¾®è°ƒæ•°æ®å·¥å‚")
    st.markdown("""
    è¿™é‡Œå­˜æ”¾äº†ä½ åœ¨å‰å°æ ¡å‡†è¿‡çš„æ‰€æœ‰æ•°æ®ã€‚
    **ä½¿ç”¨æ­¥éª¤:**
    1. ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸‹è½½ `dataset.json`ã€‚
    2. å°†æ–‡ä»¶æ”¾å…¥æœåŠ¡å™¨ `LLaMA-Factory/data` æ–‡ä»¶å¤¹ã€‚
    3. å¯åŠ¨ LLaMA-Factory WebUI è¿›è¡Œå¾®è°ƒã€‚
    """)
    
    if PATHS['training_data'].exists():
        with open(PATHS['training_data'], 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
            
        st.write(f"ğŸ“Š å½“å‰å·²ç§¯ç´¯ä¼˜è´¨æ•°æ®: **{len(raw_data)}** æ¡")
        
        # æ•°æ®é¢„è§ˆ
        with st.expander("ğŸ” é¢„è§ˆæœ€å 3 æ¡æ•°æ®"):
            st.json(raw_data[-3:] if len(raw_data) > 3 else raw_data)
        
        # ä¸‹è½½æŒ‰é’®
        json_str = json.dumps(raw_data, ensure_ascii=False, indent=2)
        st.download_button(
            label="â¬‡ï¸ ä¸‹è½½ dataset.json (LLaMA-Factoryä¸“ç”¨)",
            data=json_str,
            file_name="tea_finetune.json",
            mime="application/json"
        )
    else:
        st.warning("æš‚æ— æ•°æ®ï¼Œè¯·å»ã€äº¤äº’è¯„åˆ†ä¸æ ¡å‡†ã€‘é¡µé¢è¿›è¡Œæ‰“æ ‡ã€‚")

    st.markdown("---")
    st.subheader("ğŸ“š RAG çŸ¥è¯†åº“ç®¡ç†")
    up_files = st.file_uploader("ä¸Šä¼  PDF/TXT è¡¥å……çŸ¥è¯†åº“", accept_multiple_files=True)
    if up_files and st.button("æ›´æ–°çŸ¥è¯†åº“"):
        with st.spinner("æ­£åœ¨å‘é‡åŒ–..."):
            raw_text = ""
            for f in up_files:
                if f.name.endswith(".txt"): raw_text += f.read().decode("utf-8")
                elif f.name.endswith(".pdf"): 
                    reader = PdfReader(f)
                    for page in reader.pages: raw_text += page.extract_text()
            
            # ç®€å•åˆ‡åˆ†
            chunk_size = 300
            chunks = [raw_text[i:i+chunk_size] for i in range(0, len(raw_text), chunk_size)]
            
            # å‘é‡åŒ–
            vecs = st.session_state.embedder.encode(chunks)
            st.session_state.kb[0].add(vecs)
            st.session_state.kb[1].extend(chunks)
            
            # ä¿å­˜
            DataManager.save(st.session_state.kb[0], st.session_state.kb[1], PATHS['kb_index'], PATHS['kb_chunks'])
            st.success(f"å·²æ–°å¢ {len(chunks)} æ¡çŸ¥è¯†ç‰‡æ®µï¼")
